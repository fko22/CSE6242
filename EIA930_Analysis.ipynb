{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc6ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.0.3\n",
      "  Using cached pandas-2.0.3-cp39-cp39-macosx_10_9_x86_64.whl (11.8 MB)\n",
      "Collecting numpy==1.24.4\n",
      "  Using cached numpy-1.24.4-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "Collecting scikit-learn==1.3.2\n",
      "  Using cached scikit_learn-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "Collecting pyvis==0.3.2\n",
      "  Using cached pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "Collecting networkx==3.1\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting matplotlib==3.7.2\n",
      "  Using cached matplotlib-3.7.2-cp39-cp39-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "Collecting geopandas==0.14.4\n",
      "  Using cached geopandas-0.14.4-py3-none-any.whl (1.1 MB)\n",
      "Collecting fiona==1.9.6\n",
      "  Using cached fiona-1.9.6-cp39-cp39-macosx_10_15_x86_64.whl (18.7 MB)\n",
      "Collecting streamlit_folium==0.23.2\n",
      "  Using cached streamlit_folium-0.23.2-py3-none-any.whl (328 kB)\n",
      "Collecting seaborn==0.13.2\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Collecting lightgbm==4.5.0\n",
      "  Using cached lightgbm-4.5.0-py3-none-macosx_10_15_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from pandas==2.0.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.5.0\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl (39.4 MB)\n",
      "Collecting jsonpickle>=1.4.1\n",
      "  Using cached jsonpickle-4.0.0-py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from pyvis==0.3.2->-r requirements.txt (line 4)) (8.18.1)\n",
      "Collecting jinja2>=2.9.6\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Collecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.55.0-cp39-cp39-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached pillow-11.0.0-cp39-cp39-macosx_10_10_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (24.2)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl (265 kB)\n",
      "Collecting pyproj>=3.3.0\n",
      "  Using cached pyproj-3.6.1-cp39-cp39-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "Collecting shapely>=1.8.0\n",
      "  Using cached shapely-2.0.6-cp39-cp39-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "Requirement already satisfied: importlib-metadata in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (8.5.0)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Requirement already satisfied: six in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (1.16.0)\n",
      "Collecting attrs>=19.2.0\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Collecting click-plugins>=1.0\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting cligj>=0.5\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Collecting click~=8.0\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting branca\n",
      "  Using cached branca-0.8.0-py3-none-any.whl (25 kB)\n",
      "Collecting folium!=0.15.0,>=0.13\n",
      "  Using cached folium-0.18.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting streamlit>=1.13.0\n",
      "  Using cached streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n",
      "Collecting xyzservices\n",
      "  Using cached xyzservices-2024.9.0-py3-none-any.whl (85 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.2->-r requirements.txt (line 6)) (3.21.0)\n",
      "Requirement already satisfied: decorator in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.1.7)\n",
      "Requirement already satisfied: typing-extensions in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.19.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (3.0.48)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: stack-data in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.6.3)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_10_9_universal2.whl (14 kB)\n",
      "Collecting cachetools<6,>=4.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting protobuf<6,>=3.20\n",
      "  Using cached protobuf-5.28.3-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
      "Collecting tenacity<10,>=8.1.0\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting pyarrow>=7.0\n",
      "  Using cached pyarrow-18.0.0.tar.gz (1.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting altair<6,>=4.0\n",
      "  Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (6.4.2)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Collecting narwhals>=1.14.2\n",
      "  Using cached narwhals-1.14.2-py3-none-any.whl (225 kB)\n",
      "Collecting jsonschema>=3.0\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.2.13)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.0-cp39-cp39-macosx_10_9_x86_64.whl (125 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: pure-eval in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (2.4.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.21.0-cp39-cp39-macosx_10_12_x86_64.whl (327 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: pyarrow\n",
      "  Building wheel for pyarrow (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyarrow \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[832 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/orc.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/conftest.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_generated_version.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute_docstrings.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/util.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/flight.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cffi.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/substrait.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/dataset.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cuda.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/feather.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas_compat.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/fs.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/acero.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/csv.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/jvm.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/json.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compute.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pyarrow.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pyarrow.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to pyarrow.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pyarrow.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m ERROR setuptools_scm._file_finders.git listing git files failed - pretending there aren't any\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../LICENSE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../NOTICE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '#*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching '.asv'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.includes' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.includes' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.includes' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.includes' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.includes' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.feather' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.feather' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.feather' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.feather' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.feather' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.orc' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.orc' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.orc' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.orc' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.orc' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_azurefs.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_orc.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet_encryption.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dlpack.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_feather.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_flight.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_gcsfs.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_hdfs.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_s3fs.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_substrait.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/array.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/builder.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compat.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/config.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/device.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/error.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/gandiva.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/io.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/memory.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas-shim.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/public-api.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/scalar.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/table.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tensor.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.pxi -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/__init__.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/common.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_acero.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_cuda.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset_parquet.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_feather.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_flight.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_fs.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_python.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_substrait.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libgandiva.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libparquet_encryption.pxd -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/__init__.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/buffer.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/column.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/dataframe.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/from_dataframe.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/__init__.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/core.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/encryption.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/CMakeLists.txt -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/api.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_python_internal.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/async.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/deserialize.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/deserialize.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/iterators.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_internal.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_interop.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pch.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/platform.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_api.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_lib.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/serialize.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/serialize.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/type_traits.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.cc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/visibility.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/CMakeLists.txt -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/pythoncapi_compat.h -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/__init__.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_16597.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_39313.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_7980.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/bound_function_visit_strings.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/conftest.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/extensions.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_examples.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_threaded_import.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pyarrow_cython_example.pyx -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/read_record_batch.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/strategies.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_acero.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_adhoc_memory_leak.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_array.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_builder.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cffi.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_compute.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_convert_builtin.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cpp_internals.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_csv.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda_numba_interop.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cython.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset_encryption.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_deprecations.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_device.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dlpack.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_exec_plan.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_extension_type.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_feather.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight_async.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_fs.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gandiva.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gdb.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_io.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_ipc.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_json.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_jvm.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_memory.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_misc.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_orc.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_pandas.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_scalars.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_schema.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_sparse_tensor.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_strategies.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_substrait.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_table.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_tensor.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_types.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_udf.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_util.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_without_numpy.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/util.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/wsgi_examples.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/feather/v0.17.0.version.2-compression.lz4.feather -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/README.md -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.orc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.jsn.gz -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.orc -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.parquet -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/__init__.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_conversion.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_interchange_spec.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/__init__.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/common.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/conftest.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/encryption.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_basic.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_compliant_nested_type.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_data_types.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_dataset.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_datetime.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_encryption.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_metadata.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_pandas.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_file.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_writer.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/__init__.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/docscrape.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/version.py -> build/lib.macosx-12.7-x86_64-cpython-39/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-install-m75k_dyi/pyarrow_3728724aa24443669c5d610aedc4f65b/build/temp.macosx-12.7-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m -- Running cmake for PyArrow\n",
      "  \u001b[31m   \u001b[0m cmake -DCMAKE_INSTALL_PREFIX=/private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-install-m75k_dyi/pyarrow_3728724aa24443669c5d610aedc4f65b/build/lib.macosx-12.7-x86_64-cpython-39/pyarrow -DPYTHON_EXECUTABLE=/Users/franciso/.pyenv/versions/3.9.20/envs/myenv/bin/python -DPython3_EXECUTABLE=/Users/franciso/.pyenv/versions/3.9.20/envs/myenv/bin/python -DPYARROW_CXXFLAGS= -DPYARROW_BUNDLE_ARROW_CPP=off -DPYARROW_BUNDLE_CYTHON_CPP=off -DPYARROW_GENERATE_COVERAGE=off -DCMAKE_BUILD_TYPE=release /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-install-m75k_dyi/pyarrow_3728724aa24443669c5d610aedc4f65b\n",
      "  \u001b[31m   \u001b[0m -- The C compiler identification is AppleClang 12.0.0.12000032\n",
      "  \u001b[31m   \u001b[0m -- The CXX compiler identification is AppleClang 12.0.0.12000032\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features - done\n",
      "  \u001b[31m   \u001b[0m -- System processor: x86_64\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CXX_SUPPORTS_SSE4_2\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CXX_SUPPORTS_SSE4_2 - Success\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CXX_SUPPORTS_AVX2\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CXX_SUPPORTS_AVX2 - Success\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CXX_SUPPORTS_AVX512\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CXX_SUPPORTS_AVX512 - Success\n",
      "  \u001b[31m   \u001b[0m -- Arrow build warning level: PRODUCTION\n",
      "  \u001b[31m   \u001b[0m -- Build Type: RELEASE\n",
      "  \u001b[31m   \u001b[0m -- CMAKE_C_FLAGS:  -Wall -Wno-unknown-warning-option -Wno-pass-failed -msse4.2  -Qunused-arguments -fcolor-diagnostics  -fno-omit-frame-pointer -Wno-unused-variable -Wno-maybe-uninitialized -Wno-parentheses-equality -Wno-constant-logical-operand -Wno-missing-declarations -Wno-sometimes-uninitialized -Wno-return-type-c-linkage\n",
      "  \u001b[31m   \u001b[0m -- CMAKE_CXX_FLAGS:  -fno-aligned-new  -Wall -Wno-unknown-warning-option -Wno-pass-failed -msse4.2  -Qunused-arguments -fcolor-diagnostics  -fno-omit-frame-pointer -Wno-unused-variable -Wno-maybe-uninitialized -Wno-parentheses-equality -Wno-constant-logical-operand -Wno-missing-declarations -Wno-sometimes-uninitialized -Wno-return-type-c-linkage\n",
      "  \u001b[31m   \u001b[0m -- Generator: Unix Makefiles\n",
      "  \u001b[31m   \u001b[0m -- Build output directory: /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-install-m75k_dyi/pyarrow_3728724aa24443669c5d610aedc4f65b/build/temp.macosx-12.7-x86_64-cpython-39/release\n",
      "  \u001b[31m   \u001b[0m -- Found Python3: /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/bin/python (found version \"3.9.20\") found components: Interpreter Development.Module NumPy\n",
      "  \u001b[31m   \u001b[0m -- Found Python3Alt: /Users/franciso/.pyenv/versions/3.9.20/envs/myenv/bin/python\n",
      "  \u001b[31m   \u001b[0m -- Found NumPy version: 2.0.2\n",
      "  \u001b[31m   \u001b[0m -- NumPy include dir: /private/var/folders/4d/rvzcdc9s56l8v3t7lb_wz0jr0000gn/T/pip-build-env-hax71vpn/overlay/lib/python3.9/site-packages/numpy/_core/include\n",
      "  \u001b[31m   \u001b[0m -- Found Cython version: 3.0.11\n",
      "  \u001b[31m   \u001b[0m \u001b[31mCMake Error at CMakeLists.txt:274 (find_package):\n",
      "  \u001b[31m   \u001b[0m   By not providing \"FindArrow.cmake\" in CMAKE_MODULE_PATH this project has\n",
      "  \u001b[31m   \u001b[0m   asked CMake to find a package configuration file provided by \"Arrow\", but\n",
      "  \u001b[31m   \u001b[0m   CMake did not find one.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   Could not find a package configuration file provided by \"Arrow\" with any of\n",
      "  \u001b[31m   \u001b[0m   the following names:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     ArrowConfig.cmake\n",
      "  \u001b[31m   \u001b[0m     arrow-config.cmake\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   Add the installation prefix of \"Arrow\" to CMAKE_PREFIX_PATH or set\n",
      "  \u001b[31m   \u001b[0m   \"Arrow_DIR\" to a directory containing one of the above files.  If \"Arrow\"\n",
      "  \u001b[31m   \u001b[0m   provides a separate development package or SDK, be sure it has been\n",
      "  \u001b[31m   \u001b[0m   installed.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[0m\n",
      "  \u001b[31m   \u001b[0m -- Configuring incomplete, errors occurred!\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/local/bin/cmake' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pyarrow\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build pyarrow\n",
      "\u001b[31mERROR: Could not build wheels for pyarrow, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e475765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import zipfile\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from pages.visualizations import extract_zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ba36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compress_to_zip(filename, df):\n",
    "    csv_path = f\"./data/{filename}.csv\"\n",
    "    zip_path = f\"./data/{filename}.zip\"\n",
    "    df.to_csv(csv_path, index=True) \n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(csv_path, os.path.basename(csv_path))\n",
    "\n",
    "    print(f\"DataFrame saved and compressed into: {zip_path}\")\n",
    "    os.remove(csv_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ebf295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        state   latitude   longitude  \\\n",
      "0     Alabama  32.789907  -86.827783   \n",
      "1      Alaska  64.220419 -152.542689   \n",
      "2     Arizona  34.293393 -111.663296   \n",
      "3    Arkansas  34.898249  -92.440920   \n",
      "4  California  37.253895 -119.614389   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-87.359 35.001, -85.607 34.985, -85....  \n",
      "1  MULTIPOLYGON (((-131.602 55.118, -131.569 55.2...  \n",
      "2  POLYGON ((-109.043 37.000, -109.048 31.332, -1...  \n",
      "3  POLYGON ((-94.474 36.502, -90.153 36.496, -90....  \n",
      "4  POLYGON ((-123.233 42.006, -122.379 42.012, -1...  \n",
      "DataFrame saved and compressed into: ./data/state_coordinates.zip\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "file_path = \"./data/us-states.json\"\n",
    "    \n",
    "    # Read the GeoJSON data using geopandas\n",
    "with open(file_path, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "features = geojson_data[\"features\"]\n",
    "    \n",
    "# Create a list of geometries (Polygons)\n",
    "geometries = [shape(feature[\"geometry\"]) for feature in features]\n",
    "\n",
    "# Create a list of state names\n",
    "state_names = [feature[\"properties\"][\"name\"] for feature in features]\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame({'state': state_names, 'geometry': geometries})\n",
    "\n",
    "# Calculate centroids (latitude and longitude)\n",
    "gdf['centroid'] = gdf.geometry.centroid\n",
    "gdf['latitude'] = gdf['centroid'].apply(lambda x: x.y)\n",
    "gdf['longitude'] = gdf['centroid'].apply(lambda x: x.x)\n",
    "\n",
    "# Extract relevant columns\n",
    "\n",
    "state_coordinates = gdf[['state', 'latitude', 'longitude', 'geometry']]\n",
    "print(state_coordinates.head())\n",
    "\n",
    "compress_to_zip(\"state_coordinates\",state_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c974daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved and compressed into: ./data/EIA930LoadAndForecast_with_states.zip\n",
      "        respondent type type_name              period     value  revision_id  \\\n",
      "0             BANC    D    Demand 2022-01-02 02:00:00   2091.00       302352   \n",
      "1             PSEI    D    Demand 2022-01-02 02:00:00   4437.00       302352   \n",
      "2               SW    D    Demand 2022-01-02 02:00:00  12142.00       302352   \n",
      "3             WACM    D    Demand 2022-01-02 02:00:00   3212.00       302352   \n",
      "4             MISO    D    Demand 2022-01-02 02:00:00  74428.00       302352   \n",
      "...            ...  ...       ...                 ...       ...          ...   \n",
      "7715101        TEN    D    Demand 2024-07-04 06:00:00  20502.36       579043   \n",
      "7715102        GVL    D    Demand 2024-07-04 06:00:00    256.00       579043   \n",
      "7715103       PACW    D    Demand 2024-07-04 06:00:00   2495.00       579043   \n",
      "7715104       NEVP    D    Demand 2024-07-04 06:00:00   6843.00       579043   \n",
      "7715105       AZPS    D    Demand 2024-07-04 06:00:00   6251.00       579043   \n",
      "\n",
      "               id       state  Monday  Tuesday  Wednesday  Thursday  Friday  \\\n",
      "0            7531  California       0        0          0         0       0   \n",
      "1            7532  California       0        0          0         0       0   \n",
      "2            7533     Arizona       0        0          0         0       0   \n",
      "3            7534     Arizona       0        0          0         0       0   \n",
      "4            7535    Michigan       0        0          0         0       0   \n",
      "...           ...         ...     ...      ...        ...       ...     ...   \n",
      "7715101  17019460   Tennessee       0        0          0         1       0   \n",
      "7715102  17019461     Georgia       0        0          0         1       0   \n",
      "7715103  17019462  California       0        0          0         1       0   \n",
      "7715104  17019463      Nevada       0        0          0         1       0   \n",
      "7715105  17019464     Arizona       0        0          0         1       0   \n",
      "\n",
      "         Sunday  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "...         ...  \n",
      "7715101       0  \n",
      "7715102       0  \n",
      "7715103       0  \n",
      "7715104       0  \n",
      "7715105       0  \n",
      "\n",
      "[2943879 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Hand mapped respondent to state\n",
    "respondent_to_state = {\n",
    "    'BANC': 'California', 'PSEI': 'California', 'SW': 'Arizona', 'WACM': 'Arizona', 'MISO': 'Michigan', 'SCEG': 'South Carolina',\n",
    "    'SPA': 'Texas', 'NY': 'New York', 'GVL': 'Georgia', 'FPL': 'Florida', 'PSCO': 'Colorado', 'DUK': 'North Carolina', \n",
    "    'ISNE': 'Massachusetts', 'HST': 'Texas', 'DOPD': 'Texas', 'US48': 'North America', 'PJM': 'Pennsylvania', 'AZPS': 'Arizona', \n",
    "    'CHPD': 'Texas', 'LDWP': 'California', 'SC': 'South Carolina', 'PNM': 'New Mexico', 'FMPP': 'Florida', 'FLA': 'Florida', \n",
    "    'SCL': 'California', 'IID': 'California', 'SWPP': 'Arkansas', 'WAUW': 'Washington', 'TEX': 'Texas', 'MIDA': 'Michigan', \n",
    "    'SOCO': 'Georgia', 'NEVP': 'Nevada', 'BPAT': 'Washington', 'ERCO': 'Texas', 'NW': 'Montana', 'CAR': 'North Carolina', \n",
    "    'FPC': 'Florida', 'GCPD': 'Texas', 'AECI': 'Missouri', 'PACW': 'California', 'MIDW': 'Wisconsin', 'CPLE': 'Florida', \n",
    "    'JEA': 'Florida', 'SRP': 'Arizona', 'PGE': 'California', 'TEN': 'Tennessee', 'CAL': 'California', 'IPCO': 'Oklahoma', \n",
    "    'AVA': 'Georgia', 'SEC': 'Texas', 'CISO': 'California', 'LGEE': 'Florida', 'TAL': 'Florida', 'TEC': 'Texas', \n",
    "    'NYIS': 'New York', 'TVA': 'Tennessee', 'CPLW': 'Texas', 'TPWR': 'Texas', 'CENT': 'Texas', 'TIDC': 'Texas', \n",
    "    'SE': 'Texas', 'WALC': 'Arizona', 'PACE': 'Utah', 'EPE': 'Texas', 'TEPC': 'Texas', 'NWMT': 'Montana', \n",
    "    'NE': 'Nebraska'\n",
    "}\n",
    "\n",
    "# Load data\n",
    "data = extract_zip(\"EIA930LoadAndForecast\")\n",
    "\n",
    "data[\"state\"] = data[\"respondent\"].map(respondent_to_state)\n",
    "\n",
    "# Save the updated dataset\n",
    "compress_to_zip(\"EIA930LoadAndForecast_with_states\",data)\n",
    "# Data cleaning and transformation\n",
    "data['value'] = pd.to_numeric(data['value'], errors='coerce')\n",
    "data['period'] = pd.to_datetime(data['period'])\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Sunday']\n",
    "for day in days:\n",
    "    data[day] = (data['period'].dt.day_name() == day).astype(int)\n",
    "data = data.dropna().query(\"period.dt.year >= 2022\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379d0cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved and compressed into: ./data/data_imputed.zip\n",
      "1 of 5\n",
      "2 of 5\n",
      "3 of 5\n",
      "4 of 5\n",
      "5 of 5\n",
      "DataFrame saved and compressed into: ./data/raw_imputed.zip\n",
      "1471658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Mark anomalies\n",
    "def mark_anomalies(data):\n",
    "    data['is_zero'] = (data['value'] == 0).astype(int)\n",
    "    data['is_negative'] = (data['value'] < 0).astype(int)\n",
    "    \n",
    "    data['is_spike'] = data.groupby(['respondent', 'type_name'])['value'].transform(lambda x: (x > x.quantile(0.999)).astype(int))\n",
    "    data['is_spike'] = data['is_spike'].fillna(0)\n",
    "    return data\n",
    "\n",
    "# Impute data\n",
    "def impute_data(data):\n",
    "    # Mark impute column\n",
    "    data['impute'] = (data['is_zero'] + data['is_negative'] + data['is_spike'] > 0).astype(int)\n",
    "    \n",
    "    # Split into actuals and forecast\n",
    "    actuals = data[data['type_name'] == \"Demand\"]\n",
    "    forecast = data[data['type_name'] == \"Day-ahead demand forecast\"]\n",
    "    \n",
    "    # Merge actuals with forecast\n",
    "    joined = pd.merge(\n",
    "        actuals,\n",
    "        forecast.rename(columns={'value': 'forecast'}),\n",
    "        on=['respondent', 'period'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Rename columns to avoid suffixes like `_x` and `_y`\n",
    "    joined = joined.rename(columns={\n",
    "        'impute_x': 'impute',\n",
    "        'type_x': 'type',\n",
    "        'type_name_x': 'type_name',\n",
    "    })\n",
    "    \n",
    "    # Add imputed values\n",
    "    joined['imputed'] = np.where(\n",
    "        (joined['impute'] == 1) & ~joined['forecast'].isna(),\n",
    "        joined['forecast'],\n",
    "        np.where(\n",
    "            (joined['impute'] == 1) & joined['forecast'].isna() & ~joined['forecast'].shift(1).isna(),\n",
    "            joined['forecast'].shift(1),\n",
    "            np.where(\n",
    "                (joined['impute'] == 1) & joined['forecast'].isna() & joined['forecast'].shift(1).isna(),\n",
    "                joined['value'].shift(1),\n",
    "                joined['value']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Return cleaned data\n",
    "    return joined[['respondent', 'period', 'type', 'type_name', 'imputed']].rename(\n",
    "        columns={'imputed': 'value'}\n",
    "    ).drop_duplicates()\n",
    "data_marked = mark_anomalies(data)\n",
    "data_imputed = impute_data(data_marked)\n",
    "\n",
    "# Save the updated dataset\n",
    "compress_to_zip(\"data_imputed\",data_imputed)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"{i+1} of 5\")\n",
    "    data_marked = mark_anomalies(data_marked)\n",
    "    data_imputed = impute_data(data_marked)\n",
    "\n",
    "raw_imputed = pd.merge(data, data_imputed.rename(columns={'value': 'imputed'}),\n",
    "                       on=['respondent', 'type', 'type_name', 'period'], how='left')\n",
    "raw_imputed['is_imputed'] = (raw_imputed['value'] != raw_imputed['imputed']).astype(int)\n",
    "\n",
    "compress_to_zip(\"raw_imputed\",raw_imputed)\n",
    "\n",
    "print(raw_imputed['is_imputed'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb0e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved and compressed into: ./data/MAPE.zip\n",
      "DataFrame saved and compressed into: ./data/edges_with_MAPE.zip\n",
      "    node1 node2 respondent_x  MAPE_node1 respondent_y  MAPE_node2  abs_diff\n",
      "7    AECI   SPA         AECI    0.036209          SPA    1.044349  1.008140\n",
      "239   SPA  AECI          SPA    1.044349         AECI    0.036209  1.008140\n",
      "95   PSCO   PNM         PSCO    0.723519          PNM    0.063648  0.659871\n",
      "252   PNM  PSCO          PNM    0.063648         PSCO    0.723519  0.659871\n",
      "113  PSCO  WACM         PSCO    0.723519         WACM    0.142075  0.581444\n",
      "..    ...   ...          ...         ...          ...         ...       ...\n",
      "31   GCPD  BPAT         GCPD    0.023107         BPAT    0.020857  0.002250\n",
      "127  BPAT   AVA         BPAT    0.020857          AVA    0.019132  0.001726\n",
      "26    AVA  BPAT          AVA    0.019132         BPAT    0.020857  0.001726\n",
      "226   TEC  FMPP          TEC    0.046723         FMPP    0.045600  0.001123\n",
      "219  FMPP   TEC         FMPP    0.045600          TEC    0.046723  0.001123\n",
      "\n",
      "[192 rows x 7 columns]\n",
      "Duplicates found in actuals before pivot:\n",
      "        respondent type type_name              period    value  revision_id  \\\n",
      "88              NE    D    Demand 2022-01-01 00:00:00  14859.0       302352   \n",
      "89             PNM    D    Demand 2022-01-01 00:00:00   1754.0       302352   \n",
      "90            LDWP    D    Demand 2022-01-01 00:00:00   2662.0       302352   \n",
      "91            BPAT    D    Demand 2022-01-01 00:00:00   8535.0       302352   \n",
      "92            CISO    D    Demand 2022-01-01 00:00:00  22618.0       302352   \n",
      "...            ...  ...       ...                 ...      ...          ...   \n",
      "2942730       BANC    D    Demand 2024-07-05 06:00:00   3115.0       579043   \n",
      "2942731       CPLW    D    Demand 2024-07-05 06:00:00    504.0       579043   \n",
      "2942732       TIDC    D    Demand 2024-07-05 06:00:00    520.0       579043   \n",
      "2942733        DUK    D    Demand 2024-07-05 06:00:00  12678.0       579043   \n",
      "2942734        TAL    D    Demand 2024-07-05 06:00:00    346.0       579043   \n",
      "\n",
      "               id           state  Monday  Tuesday  Wednesday  Thursday  \\\n",
      "88              1        Nebraska       0        0          0         0   \n",
      "89              2      New Mexico       0        0          0         0   \n",
      "90              3      California       0        0          0         0   \n",
      "91              4      Washington       0        0          0         0   \n",
      "92              5      California       0        0          0         0   \n",
      "...           ...             ...     ...      ...        ...       ...   \n",
      "2942730  17026256      California       0        0          0         0   \n",
      "2942731  17026257           Texas       0        0          0         0   \n",
      "2942732  17026258           Texas       0        0          0         0   \n",
      "2942733  17026259  North Carolina       0        0          0         0   \n",
      "2942734  17026260         Florida       0        0          0         0   \n",
      "\n",
      "         Friday  Sunday  is_zero  is_negative  is_spike  impute  imputed  \\\n",
      "88            0       0        0            0         0       0  14859.0   \n",
      "89            0       0        0            0         0       0   1754.0   \n",
      "90            0       0        0            0         0       0   2662.0   \n",
      "91            0       0        0            0         0       0   8535.0   \n",
      "92            0       0        0            0         0       0  22618.0   \n",
      "...         ...     ...      ...          ...       ...     ...      ...   \n",
      "2942730       1       0        0            0         0       0   3115.0   \n",
      "2942731       1       0        0            0         0       0    504.0   \n",
      "2942732       1       0        0            0         0       0    520.0   \n",
      "2942733       1       0        0            0         0       0  12678.0   \n",
      "2942734       1       0        0            0         0       0    346.0   \n",
      "\n",
      "         is_imputed  \n",
      "88                0  \n",
      "89                0  \n",
      "90                0  \n",
      "91                0  \n",
      "92                0  \n",
      "...             ...  \n",
      "2942730           0  \n",
      "2942731           0  \n",
      "2942732           0  \n",
      "2942733           0  \n",
      "2942734           0  \n",
      "\n",
      "[6203 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate MAPEs\n",
    "actuals = raw_imputed[raw_imputed['type_name'] == \"Demand\"]\n",
    "forecast = raw_imputed[raw_imputed['type_name'] == \"Day-ahead demand forecast\"]\n",
    "joined = pd.merge(actuals, forecast[['respondent', 'period', 'value']].rename(columns={'value': 'forecast'}),\n",
    "                  on=['respondent', 'period'], how='left')\n",
    "joined['abs_error'] = np.abs(joined['value'] - joined['forecast']) / np.abs(joined['value'])\n",
    "\n",
    "MAPE = joined[joined['abs_error'] != np.inf].groupby('respondent')['abs_error'].mean().reset_index(name='MAPE')\n",
    "compress_to_zip(\"MAPE\",MAPE)\n",
    "\n",
    "# Load edges and calculate correlations\n",
    "edges = extract_zip(\"eia_930_edges\")\n",
    "exclude = [\"CISO\", \"ERCO\", \"SWPP\", \"MISO\", \"NYIS\", \"ISNE\", \"CAL\", \"PJM\"]\n",
    "\n",
    "edges = edges.merge(MAPE, left_on=\"node1\", right_on=\"respondent\").rename(columns={\"MAPE\": \"MAPE_node1\"})\n",
    "edges = edges.merge(MAPE, left_on=\"node2\", right_on=\"respondent\").rename(columns={\"MAPE\": \"MAPE_node2\"})\n",
    "edges['abs_diff'] = np.abs(edges['MAPE_node1'] - edges['MAPE_node2'])\n",
    "edges = edges.query(\"~node1.isin(@exclude) & ~node2.isin(@exclude)\").sort_values('abs_diff', ascending=False)\n",
    "compress_to_zip(\"edges_with_MAPE\",edges)\n",
    "print(edges)\n",
    "\n",
    "# Wide format and correlation matrix\n",
    "duplicates = actuals[actuals.duplicated(subset=['period', 'respondent'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates found in actuals before pivot:\")\n",
    "    print(duplicates)\n",
    "    # dedup\n",
    "    actuals = actuals.drop_duplicates(subset=['period', 'respondent'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20542a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respondent      AECI       AVA      AZPS      BANC      BPAT       CAL  \\\n",
      "respondent                                                               \n",
      "AECI        1.000000  0.557731  0.308503  0.373136  0.512310  0.251463   \n",
      "AVA         0.557731  1.000000  0.071045  0.356518  0.942282  0.239249   \n",
      "AZPS        0.308503  0.071045  1.000000  0.815741  0.003894  0.791049   \n",
      "BANC        0.373136  0.356518  0.815741  1.000000  0.293236  0.878408   \n",
      "BPAT        0.512310  0.942282  0.003894  0.293236  1.000000  0.176209   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "TVA         0.797252  0.404350  0.489897  0.512612  0.357459  0.369879   \n",
      "US48        0.717378  0.431817  0.695393  0.708961  0.360759  0.582142   \n",
      "WACM        0.289553  0.468788  0.308211  0.338997  0.406905  0.244657   \n",
      "WALC        0.124428 -0.128594  0.688994  0.570709 -0.168939  0.512349   \n",
      "WAUW        0.642405  0.736001  0.338746  0.484163  0.676043  0.417565   \n",
      "\n",
      "respondent       CAR      CENT      CHPD      CISO  ...       TEN      TEPC  \\\n",
      "respondent                                          ...                       \n",
      "AECI        0.646799  0.782936  0.531905  0.211368  ...  0.797038  0.357361   \n",
      "AVA         0.340112  0.414165  0.829077  0.205714  ...  0.404205  0.103178   \n",
      "AZPS        0.507912  0.668303 -0.209178  0.769579  ...  0.490314  0.909207   \n",
      "BANC        0.512089  0.648483  0.029110  0.840067  ...  0.512630  0.737478   \n",
      "BPAT        0.284407  0.348945  0.857851  0.152089  ...  0.357386  0.046146   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "TVA         0.897545  0.837036  0.255898  0.322291  ...  0.999999  0.508151   \n",
      "US48        0.892530  0.928611  0.160214  0.527250  ...  0.906653  0.683009   \n",
      "WACM        0.299967  0.411225  0.376464  0.249374  ...  0.279880  0.284825   \n",
      "WALC        0.355935  0.465931 -0.429290  0.465290  ...  0.348424  0.650285   \n",
      "WAUW        0.516668  0.623675  0.579968  0.381339  ...  0.542914  0.314832   \n",
      "\n",
      "respondent       TEX      TIDC      TPWR       TVA      US48      WACM  \\\n",
      "respondent                                                               \n",
      "AECI        0.518217  0.286387  0.433303  0.797252  0.717378  0.289553   \n",
      "AVA         0.186889  0.185116  0.877830  0.404350  0.431817  0.468788   \n",
      "AZPS        0.753437  0.869974 -0.203444  0.489897  0.695393  0.308211   \n",
      "BANC        0.652597  0.939640  0.111524  0.512612  0.708961  0.338997   \n",
      "BPAT        0.115426  0.114120  0.926417  0.357459  0.360759  0.406905   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "TVA         0.727036  0.482460  0.208124  1.000000  0.906785  0.279217   \n",
      "US48        0.867982  0.699607  0.180468  0.906785  1.000000  0.373924   \n",
      "WACM        0.324079  0.236095  0.254916  0.279217  0.373924  1.000000   \n",
      "WALC        0.610413  0.663277 -0.283244  0.348004  0.503156 -0.149298   \n",
      "WAUW        0.382380  0.379674  0.565031  0.543018  0.620350  0.378461   \n",
      "\n",
      "respondent      WALC      WAUW  \n",
      "respondent                      \n",
      "AECI        0.124428  0.642405  \n",
      "AVA        -0.128594  0.736001  \n",
      "AZPS        0.688994  0.338746  \n",
      "BANC        0.570709  0.484163  \n",
      "BPAT       -0.168939  0.676043  \n",
      "...              ...       ...  \n",
      "TVA         0.348004  0.543018  \n",
      "US48        0.503156  0.620350  \n",
      "WACM       -0.149298  0.378461  \n",
      "WALC        1.000000  0.128870  \n",
      "WAUW        0.128870  1.000000  \n",
      "\n",
      "[67 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform pivot operation\n",
    "actuals_wide = actuals.pivot(index='period', columns='respondent', values='imputed')\n",
    "correlation_matrix = actuals_wide.corr(method='pearson', min_periods=1)\n",
    "correlation_matrix.to_csv(\"./data/correlation_matrix.csv\", index=True) \n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd0e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple LDWP Model\n",
    "relevant_cols = ['CISO', 'BPAT', 'LDWP', 'PACE', 'NEVP', 'AZPS', 'WALC']\n",
    "reg_data = actuals_wide[relevant_cols].dropna()\n",
    "reg_data['LDWP_lag1'] = reg_data['LDWP'].shift(1)\n",
    "reg_data['LDWP_lag24'] = reg_data['LDWP'].shift(24)\n",
    "\n",
    "reg_data = reg_data.dropna()\n",
    "X = reg_data[['LDWP_lag1', 'LDWP_lag24', 'CISO', 'BPAT', 'PACE', 'NEVP', 'AZPS', 'WALC']]\n",
    "y = reg_data['LDWP']\n",
    "\n",
    "# Define hyperparameter grids for GridSearchCV\n",
    "linear_param_grid = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, shuffle=True, random_state=614\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46ee948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Linear Regression Model saved successfully.\n",
      "Best Random Forest Model saved successfully.\n",
      "Best Gradient Boosting Model saved successfully.\n",
      "Model Performance (MAPE):\n",
      "Linear Regression: 0.0430\n",
      "Random Forest Regressor: 0.0322\n",
      "Gradient Boosting Regressor: 0.0327\n",
      "Evaluation results saved successfully.\n",
      "Linear Model Coefficients: [ 0.86237141  0.12472476 -0.00631999  0.01101798  0.05736264 -0.0310797\n",
      "  0.01150089  0.07930391]\n",
      "Random Forest Feature Importances: [0.94671055 0.01579027 0.01025258 0.00575556 0.00784952 0.00471721\n",
      " 0.00330078 0.00562353]\n",
      "Gradient Boosting Feature Importances: [0.94347466 0.01569727 0.0119251  0.00652526 0.00788263 0.00463366\n",
      " 0.00462161 0.00523981]\n",
      "Results saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Model 1: Linear Regression with GridSearchCV and Cross-Validation\n",
    "linear_model = LinearRegression()\n",
    "linear_grid_search = GridSearchCV(linear_model, linear_param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "linear_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Linear Regression Model\n",
    "best_linear_model = linear_grid_search.best_estimator_\n",
    "linear_predictions = best_linear_model.predict(X_test)\n",
    "linear_mape = mean_absolute_percentage_error(y_test, linear_predictions)\n",
    "with open(\"./models/linear_regression_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_linear_model, f)\n",
    "print(\"Best Linear Regression Model saved successfully.\")\n",
    "\n",
    "# Model 2: Random Forest Regressor with GridSearchCV and Cross-Validation\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation for Random Forest\n",
    "rf_cv_results = cross_validate(rf_grid_search.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Best Random Forest Model\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "rf_mape = mean_absolute_percentage_error(y_test, rf_predictions)\n",
    "with open(\"./models/random_forest_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_rf_model, f)\n",
    "print(\"Best Random Forest Model saved successfully.\")\n",
    "\n",
    "# Model 3: Gradient Boosting Regressor with GridSearchCV and Cross-Validation\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_grid_search = GridSearchCV(gb_model, gb_param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation for Gradient Boosting\n",
    "gb_cv_results = cross_validate(gb_grid_search.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Best Gradient Boosting Model\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "gb_predictions = best_gb_model.predict(X_test)\n",
    "gb_mape = mean_absolute_percentage_error(y_test, gb_predictions)\n",
    "with open(\"./models/gradient_boosting_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_gb_model, f)\n",
    "print(\"Best Gradient Boosting Model saved successfully.\")\n",
    "\n",
    "# Compare model accuracy\n",
    "print(\"Model Performance (MAPE):\")\n",
    "print(f\"Linear Regression: {linear_mape:.4f}\")\n",
    "print(f\"Random Forest Regressor: {rf_mape:.4f}\")\n",
    "print(f\"Gradient Boosting Regressor: {gb_mape:.4f}\")\n",
    "\n",
    "# Evaluation results dictionary\n",
    "evaluation_results = {\n",
    "    \"Linear Regression\": {\"MAPE\": linear_mape},\n",
    "    \"Random Forest\": {\"MAPE\": rf_mape},\n",
    "    \"Gradient Boosting\": {\"MAPE\": gb_mape},\n",
    "}\n",
    "\n",
    "# Save evaluation results to JSON\n",
    "with open(\"./data/evaluation_results.json\", \"w\") as file:\n",
    "    json.dump(evaluation_results, file)\n",
    "\n",
    "print(\"Evaluation results saved successfully.\")\n",
    "\n",
    "# Print model coefficients or feature importances\n",
    "print(\"Linear Model Coefficients:\", best_linear_model.coef_)\n",
    "print(\"Random Forest Feature Importances:\", best_rf_model.feature_importances_)\n",
    "print(\"Gradient Boosting Feature Importances:\", best_gb_model.feature_importances_)\n",
    "\n",
    "print(\"Results saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "281a4803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Models Performance (MAPE):\n",
      "Stacking Model 1 (Linear + RF): 0.0333\n",
      "Stacking Model 2 (Linear + GB): 0.0344\n"
     ]
    }
   ],
   "source": [
    "base_models_1 = [\n",
    "    ('linear', best_linear_model),\n",
    "    ('rf', best_rf_model)\n",
    "]\n",
    "\n",
    "base_models_2 = [\n",
    "    ('linear', best_linear_model),\n",
    "    ('gb', best_gb_model)\n",
    "]\n",
    "\n",
    "base_models_3 = [\n",
    "    ('rf', best_rf_model),\n",
    "    ('gb', best_gb_model)\n",
    "]\n",
    "\n",
    "# Linear Regression Models with different hyperparameters (create multiple models)\n",
    "linear_model_1 = LinearRegression(fit_intercept=True)\n",
    "linear_model_2 = LinearRegression(fit_intercept=False)\n",
    "\n",
    "\n",
    "# Create a dictionary to hold the models\n",
    "stacking_results = {}\n",
    "\n",
    "# Stacking Regressors\n",
    "stacking_model_1 = StackingRegressor(estimators=base_models_1, final_estimator=linear_model_1)\n",
    "stacking_model_2 = StackingRegressor(estimators=base_models_2, final_estimator=linear_model_2)\n",
    "# Train each stacking model\n",
    "stacking_model_1.fit(X_train, y_train)\n",
    "stacking_model_2.fit(X_train, y_train)\n",
    "\n",
    "# Predictions for each model\n",
    "stacking_predictions_1 = stacking_model_1.predict(X_test)\n",
    "stacking_predictions_2 = stacking_model_2.predict(X_test)\n",
    "\n",
    "# Calculate MAPE for each stacking model\n",
    "stacking_mape_1 = mean_absolute_percentage_error(y_test, stacking_predictions_1)\n",
    "stacking_mape_2 = mean_absolute_percentage_error(y_test, stacking_predictions_2)\n",
    "\n",
    "# Save stacking models\n",
    "with open(\"./models/stacking_model_1.pkl\", 'wb') as f:\n",
    "    pickle.dump(stacking_model_1, f)\n",
    "with open(\"./models/stacking_model_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(stacking_model_2, f)\n",
    "\n",
    "\n",
    "# Store results\n",
    "stacking_results[\"Stacking Model 1\"] = {\"MAPE\": stacking_mape_1}\n",
    "stacking_results[\"Stacking Model 2\"] = {\"MAPE\": stacking_mape_2}\n",
    "\n",
    "evaluation_results.update(stacking_results)\n",
    "# Save evaluation results to JSON\n",
    "with open(\"./data/evaluation_results.json\", \"w\") as file:\n",
    "    json.dump(evaluation_results, file)\n",
    "\n",
    "# Output performance results\n",
    "print(\"Stacking Models Performance (MAPE):\")\n",
    "print(f\"Stacking Model 1 (Linear + RF): {stacking_mape_1:.4f}\")\n",
    "print(f\"Stacking Model 2 (Linear + GB): {stacking_mape_2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b700d074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Performance (MAPE):\n",
      "Ridge: 0.0430\n",
      "MLPRegressor: 0.0419\n",
      "SVR: 0.3543\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/evaluation_results.json\", \"r\") as file:\n",
    "    evaluation_results = json.load(file) \n",
    "    \n",
    "ridge = Ridge(alpha=1.0) \n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_predictions = ridge.predict(X_test)\n",
    "ridge_mape = mean_absolute_percentage_error(y_test, ridge_predictions)\n",
    "with open(\"./models/ridge.pkl\", 'wb') as f:\n",
    "    pickle.dump(ridge, f)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,)],  \n",
    "    'activation': ['relu', 'tanh', 'logistic'],    \n",
    "    'solver': ['adam', 'sgd'],                    \n",
    "    'alpha': [0.0001, 0.001, 0.01],                \n",
    "    'learning_rate': ['constant', 'adaptive'],     \n",
    "    'max_iter': [500, 1000, 1500],                  \n",
    "}\n",
    "\n",
    "mlp = MLPRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_mlp = grid_search.best_estimator_\n",
    "mlp_predictions = best_mlp.predict(X_test)\n",
    "mlp_mape = mean_absolute_percentage_error(y_test, mlp_predictions)\n",
    "with open(\"./models/mlp.pkl\", 'wb') as f:\n",
    "    pickle.dump(mlp, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8cb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'gamma': [0.01, 0.1, 1, 'scale'],\n",
    "    'epsilon': [0.01, 0.1, 0.5, 1.0] \n",
    "}\n",
    "\n",
    "svr = SVR(kernel='rbf')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_percentage_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_svr = grid_search.best_estimator_\n",
    "svr_predictions = best_svr.predict(X_test)\n",
    "svr_mape = mean_absolute_percentage_error(y_test, svr_predictions)\n",
    "with open(\"./models/svr.pkl\", 'wb') as f:\n",
    "    pickle.dump(svr, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store results\n",
    "results = {}\n",
    "results[\"Ridge\"] = {\"MAPE\": ridge_mape}\n",
    "results[\"MLP\"] = {\"MAPE\": mlp_mape}\n",
    "results[\"SVR\"] = {\"MAPE\": svr_mape}\n",
    "\n",
    "evaluation_results.update(results)\n",
    "# Save evaluation results to JSON\n",
    "with open(\"./data/evaluation_results.json\", \"w\") as file:\n",
    "    json.dump(evaluation_results, file)\n",
    "\n",
    "# Output performance results\n",
    "print(\"Linear Performance (MAPE):\")\n",
    "print(f\"Ridge: {ridge_mape:.4f}\")\n",
    "print(f\"MLPRegressor: {mlp_mape:.4f}\")\n",
    "print(f\"SVR: {svr_mape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127b883c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 500, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05e60c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neighbors: 3\n",
      "Best KNN Model MAPE: 0.0451\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsRegressor()\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1, 68)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Best number of neighbors: {best_n_neighbors}\")\n",
    "best_knn = grid_search.best_estimator_\n",
    "knn_predictions = best_knn.predict(X_test)\n",
    "knn_mape = mean_absolute_percentage_error(y_test, knn_predictions)\n",
    "print(f\"Best KNN Model MAPE: {knn_mape:.4f}\")\n",
    "results = {}\n",
    "results[\"KNN\"] = {\"MAPE\": knn_mape}\n",
    "evaluation_results.update(results)\n",
    "# Save evaluation results to JSON\n",
    "with open(\"./data/evaluation_results.json\", \"w\") as file:\n",
    "    json.dump(evaluation_results, file)\n",
    "with open(\"./models/knn.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_knn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0c94a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/predictions.json\", \"r\") as file:\n",
    "    predictions = json.load(file) \n",
    "updates = {}\n",
    "updates[\"Ridge\"] = ridge_predictions.tolist()\n",
    "updates[\"MLP\"] = mlp_predictions.tolist()\n",
    "updates[\"SVR\"] = svr_predictions.tolist()\n",
    "updates[\"KNN\"] = knn_predictions.tolist()\n",
    "predictions.update(updates)\n",
    "with open(\"./data/predictions.json\", \"w\") as file:\n",
    "    json.dump(predictions, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8916fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed: knn.pkl -> ./models/knn.pkl.gz\n",
      "Deleted original file: knn.pkl\n",
      "Compressed: ridge.pkl -> ./models/ridge.pkl.gz\n",
      "Deleted original file: ridge.pkl\n",
      "Compressed: mlp.pkl -> ./models/mlp.pkl.gz\n",
      "Deleted original file: mlp.pkl\n",
      "Compressed: svr.pkl -> ./models/svr.pkl.gz\n",
      "Deleted original file: svr.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import gzip\n",
    "\n",
    "# with zipfile.ZipFile('./models/stacking_model_1.zip', 'r') as zipf:\n",
    "#     zipf.extractall('./')\n",
    "#     print(zipf.namelist())\n",
    "folder_path = \"./models\"\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a pickle file\n",
    "    if file_name.endswith('.pkl'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        compressed_file_path = file_path + '.gz'  # Add .gz extension\n",
    "        \n",
    "        # Read the pickle file\n",
    "        with open(file_path, 'rb') as f_in:\n",
    "            data = pickle.load(f_in)\n",
    "        \n",
    "        with gzip.open(compressed_file_path, 'wb') as f_out:\n",
    "            pickle.dump(data, f_out)\n",
    "        \n",
    "        print(f\"Compressed: {file_name} -> {compressed_file_path}\")\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted original file: {file_name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b36dfd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 25308793 bytes\n",
      "File size: 24715.62 KB\n",
      "File size: 24.14 MB\n",
      "File size: 112608325 bytes\n",
      "File size: 109969.07 KB\n",
      "File size: 107.39 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = './models/random_forest_model.pkl.gz'\n",
    "\n",
    "# Get file size in bytes\n",
    "file_size = os.path.getsize(file_path)\n",
    "\n",
    "# Convert to KB or MB for readability\n",
    "file_size_kb = file_size / 1024  # Convert to KB\n",
    "file_size_mb = file_size_kb / 1024  # Convert to MB\n",
    "\n",
    "print(f\"File size: {file_size} bytes\")\n",
    "print(f\"File size: {file_size_kb:.2f} KB\")\n",
    "print(f\"File size: {file_size_mb:.2f} MB\")\n",
    "\n",
    "file_path = './models/random_forest_model.pkl'\n",
    "\n",
    "# Get file size in bytes\n",
    "file_size = os.path.getsize(file_path)\n",
    "\n",
    "# Convert to KB or MB for readability\n",
    "file_size_kb = file_size / 1024  # Convert to KB\n",
    "file_size_mb = file_size_kb / 1024  # Convert to MB\n",
    "\n",
    "print(f\"File size: {file_size} bytes\")\n",
    "print(f\"File size: {file_size_kb:.2f} KB\")\n",
    "print(f\"File size: {file_size_mb:.2f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3a86de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Actual', 'Linear Regression', 'Random Forest', 'Gradient Boosting', 'Stacking Model 1', 'Stacking Model 2', 'Ridge', 'MLP', 'SVR', 'KNN'])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/predictions.json\", \"r\") as file:\n",
    "    predictions = json.load(file) \n",
    "print(predictions.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
