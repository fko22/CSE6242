{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc6ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.0.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: numpy==1.24.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: pyvis==0.3.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.3.2)\n",
      "Requirement already satisfied: networkx==3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (3.1)\n",
      "Requirement already satisfied: matplotlib==3.7.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (3.7.2)\n",
      "Requirement already satisfied: geopandas==0.14.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.14.4)\n",
      "Requirement already satisfied: fiona==1.9.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (1.9.6)\n",
      "Collecting streamlit_folium==0.23.2\n",
      "  Downloading streamlit_folium-0.23.2-py3-none-any.whl (328 kB)\n",
      "\u001b[K     |████████████████████████████████| 328 kB 650 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas==2.0.3->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas==2.0.3->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from pandas==2.0.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyvis==0.3.2->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyvis==0.3.2->-r requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyvis==0.3.2->-r requirements.txt (line 4)) (8.12.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (1.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (4.55.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib==3.7.2->-r requirements.txt (line 6)) (6.4.5)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from geopandas==0.14.4->-r requirements.txt (line 7)) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from geopandas==0.14.4->-r requirements.txt (line 7)) (2.0.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (24.2.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (2024.8.30)\n",
      "Requirement already satisfied: cligj>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.10\" in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (8.5.0)\n",
      "Requirement already satisfied: six in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: click~=8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from fiona==1.9.6->-r requirements.txt (line 8)) (1.1.1)\n",
      "Collecting folium!=0.15.0,>=0.13\n",
      "  Downloading folium-0.18.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting branca\n",
      "  Downloading branca-0.8.0-py3-none-any.whl (25 kB)\n",
      "Collecting streamlit>=1.13.0\n",
      "  Downloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.6 MB 17.0 MB/s eta 0:00:01     |█████                           | 1.3 MB 17.0 MB/s eta 0:00:01     |███████▋                        | 2.0 MB 17.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2>=2.9.6->pyvis==0.3.2->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.1.4)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (5.14.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (3.0.48)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.1.7)\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.7.5)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: decorator in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib==3.7.2->-r requirements.txt (line 6)) (3.20.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from folium!=0.15.0,>=0.13->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (2.32.3)\n",
      "Collecting xyzservices\n",
      "  Downloading xyzservices-2024.9.0-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 4.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tenacity<10,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (8.5.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (13.9.3)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (4.2.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (16.1.0)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (0.8.0b4)\n",
      "Collecting cachetools<6,>=4.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (4.25.3)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (6.4.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.2.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/franciso/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=5.3.0->pyvis==0.3.2->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->folium!=0.15.0,>=0.13->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->folium!=0.15.0,>=0.13->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->folium!=0.15.0,>=0.13->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (3.0.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (4.23.0)\n",
      "Requirement already satisfied: toolz in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: entrypoints in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (0.1.2)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (0.21.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.13.0->streamlit_folium==0.23.2->-r requirements.txt (line 9)) (0.35.1)\n",
      "Installing collected packages: branca, xyzservices, folium, smmap, gitdb, gitpython, cachetools, blinker, toml, streamlit, streamlit-folium\n",
      "Successfully installed blinker-1.9.0 branca-0.8.0 cachetools-5.5.0 folium-0.18.0 gitdb-4.0.11 gitpython-3.1.43 smmap-5.0.1 streamlit-1.40.1 streamlit-folium-0.23.2 toml-0.10.2 xyzservices-2024.9.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d7c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import zipfile\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from app import extract_zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7ba36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compress_to_zip(filename, df):\n",
    "    csv_path = f\"./data/{filename}.csv\"\n",
    "    zip_path = f\"./data/{filename}.zip\"\n",
    "    df.to_csv(csv_path, index=True) \n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(csv_path, os.path.basename(csv_path))\n",
    "\n",
    "    print(f\"DataFrame saved and compressed into: {zip_path}\")\n",
    "    os.remove(csv_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62ebf295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        state   latitude   longitude  \\\n",
      "0     Alabama  32.789907  -86.827783   \n",
      "1      Alaska  64.220419 -152.542689   \n",
      "2     Arizona  34.293393 -111.663296   \n",
      "3    Arkansas  34.898249  -92.440920   \n",
      "4  California  37.253895 -119.614389   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-87.359 35.001, -85.607 34.985, -85....  \n",
      "1  MULTIPOLYGON (((-131.602 55.118, -131.569 55.2...  \n",
      "2  POLYGON ((-109.043 37.000, -109.048 31.332, -1...  \n",
      "3  POLYGON ((-94.474 36.502, -90.153 36.496, -90....  \n",
      "4  POLYGON ((-123.233 42.006, -122.379 42.012, -1...  \n",
      "DataFrame saved and compressed into: ./data/state_coordinates.zip\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "file_path = \"./data/us-states.json\"\n",
    "    \n",
    "    # Read the GeoJSON data using geopandas\n",
    "with open(file_path, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "features = geojson_data[\"features\"]\n",
    "    \n",
    "# Create a list of geometries (Polygons)\n",
    "geometries = [shape(feature[\"geometry\"]) for feature in features]\n",
    "\n",
    "# Create a list of state names\n",
    "state_names = [feature[\"properties\"][\"name\"] for feature in features]\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame({'state': state_names, 'geometry': geometries})\n",
    "\n",
    "# Calculate centroids (latitude and longitude)\n",
    "gdf['centroid'] = gdf.geometry.centroid\n",
    "gdf['latitude'] = gdf['centroid'].apply(lambda x: x.y)\n",
    "gdf['longitude'] = gdf['centroid'].apply(lambda x: x.x)\n",
    "\n",
    "# Extract relevant columns\n",
    "\n",
    "state_coordinates = gdf[['state', 'latitude', 'longitude', 'geometry']]\n",
    "print(state_coordinates.head())\n",
    "\n",
    "compress_to_zip(\"state_coordinates\",state_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c974daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: ./data/EIA930LoadAndForecast.csv\n",
      "DataFrame saved and compressed into: ./data/EIA930LoadAndForecast_with_states.zip\n",
      "        respondent type type_name              period     value  revision_id  \\\n",
      "0             BANC    D    Demand 2022-01-02 02:00:00   2091.00       302352   \n",
      "1             PSEI    D    Demand 2022-01-02 02:00:00   4437.00       302352   \n",
      "2               SW    D    Demand 2022-01-02 02:00:00  12142.00       302352   \n",
      "3             WACM    D    Demand 2022-01-02 02:00:00   3212.00       302352   \n",
      "4             MISO    D    Demand 2022-01-02 02:00:00  74428.00       302352   \n",
      "...            ...  ...       ...                 ...       ...          ...   \n",
      "7715101        TEN    D    Demand 2024-07-04 06:00:00  20502.36       579043   \n",
      "7715102        GVL    D    Demand 2024-07-04 06:00:00    256.00       579043   \n",
      "7715103       PACW    D    Demand 2024-07-04 06:00:00   2495.00       579043   \n",
      "7715104       NEVP    D    Demand 2024-07-04 06:00:00   6843.00       579043   \n",
      "7715105       AZPS    D    Demand 2024-07-04 06:00:00   6251.00       579043   \n",
      "\n",
      "               id       state  Monday  Tuesday  Wednesday  Thursday  Friday  \\\n",
      "0            7531  California       0        0          0         0       0   \n",
      "1            7532  California       0        0          0         0       0   \n",
      "2            7533     Arizona       0        0          0         0       0   \n",
      "3            7534     Arizona       0        0          0         0       0   \n",
      "4            7535    Michigan       0        0          0         0       0   \n",
      "...           ...         ...     ...      ...        ...       ...     ...   \n",
      "7715101  17019460   Tennessee       0        0          0         1       0   \n",
      "7715102  17019461     Georgia       0        0          0         1       0   \n",
      "7715103  17019462  California       0        0          0         1       0   \n",
      "7715104  17019463      Nevada       0        0          0         1       0   \n",
      "7715105  17019464     Arizona       0        0          0         1       0   \n",
      "\n",
      "         Sunday  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n",
      "...         ...  \n",
      "7715101       0  \n",
      "7715102       0  \n",
      "7715103       0  \n",
      "7715104       0  \n",
      "7715105       0  \n",
      "\n",
      "[2943879 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Hand mapped respondent to state\n",
    "respondent_to_state = {\n",
    "    'BANC': 'California', 'PSEI': 'California', 'SW': 'Arizona', 'WACM': 'Arizona', 'MISO': 'Michigan', 'SCEG': 'South Carolina',\n",
    "    'SPA': 'Texas', 'NY': 'New York', 'GVL': 'Georgia', 'FPL': 'Florida', 'PSCO': 'Colorado', 'DUK': 'North Carolina', \n",
    "    'ISNE': 'Massachusetts', 'HST': 'Texas', 'DOPD': 'Texas', 'US48': 'North America', 'PJM': 'Pennsylvania', 'AZPS': 'Arizona', \n",
    "    'CHPD': 'Texas', 'LDWP': 'California', 'SC': 'South Carolina', 'PNM': 'New Mexico', 'FMPP': 'Florida', 'FLA': 'Florida', \n",
    "    'SCL': 'California', 'IID': 'California', 'SWPP': 'Arkansas', 'WAUW': 'Washington', 'TEX': 'Texas', 'MIDA': 'Michigan', \n",
    "    'SOCO': 'Georgia', 'NEVP': 'Nevada', 'BPAT': 'Washington', 'ERCO': 'Texas', 'NW': 'Montana', 'CAR': 'North Carolina', \n",
    "    'FPC': 'Florida', 'GCPD': 'Texas', 'AECI': 'Missouri', 'PACW': 'California', 'MIDW': 'Wisconsin', 'CPLE': 'Florida', \n",
    "    'JEA': 'Florida', 'SRP': 'Arizona', 'PGE': 'California', 'TEN': 'Tennessee', 'CAL': 'California', 'IPCO': 'Oklahoma', \n",
    "    'AVA': 'Georgia', 'SEC': 'Texas', 'CISO': 'California', 'LGEE': 'Florida', 'TAL': 'Florida', 'TEC': 'Texas', \n",
    "    'NYIS': 'New York', 'TVA': 'Tennessee', 'CPLW': 'Texas', 'TPWR': 'Texas', 'CENT': 'Texas', 'TIDC': 'Texas', \n",
    "    'SE': 'Texas', 'WALC': 'Arizona', 'PACE': 'Utah', 'EPE': 'Texas', 'TEPC': 'Texas', 'NWMT': 'Montana', \n",
    "    'NE': 'Nebraska'\n",
    "}\n",
    "\n",
    "# Load data\n",
    "data = extract_zip(\"EIA930LoadAndForecast\")\n",
    "\n",
    "data[\"state\"] = data[\"respondent\"].map(respondent_to_state)\n",
    "\n",
    "# Save the updated dataset\n",
    "compress_to_zip(\"EIA930LoadAndForecast_with_states\",data)\n",
    "# Data cleaning and transformation\n",
    "data['value'] = pd.to_numeric(data['value'], errors='coerce')\n",
    "data['period'] = pd.to_datetime(data['period'])\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Sunday']\n",
    "for day in days:\n",
    "    data[day] = (data['period'].dt.day_name() == day).astype(int)\n",
    "data = data.dropna().query(\"period.dt.year >= 2022\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "379d0cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved and compressed into: ./data/data_imputed.zip\n",
      "1 of 5\n",
      "2 of 5\n",
      "3 of 5\n",
      "4 of 5\n",
      "5 of 5\n",
      "DataFrame saved and compressed into: ./data/raw_imputed.zip\n",
      "1471658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Mark anomalies\n",
    "def mark_anomalies(data):\n",
    "    data['is_zero'] = (data['value'] == 0).astype(int)\n",
    "    data['is_negative'] = (data['value'] < 0).astype(int)\n",
    "    \n",
    "    data['is_spike'] = data.groupby(['respondent', 'type_name'])['value'].transform(lambda x: (x > x.quantile(0.999)).astype(int))\n",
    "    data['is_spike'] = data['is_spike'].fillna(0)\n",
    "    return data\n",
    "\n",
    "# Impute data\n",
    "def impute_data(data):\n",
    "    # Mark impute column\n",
    "    data['impute'] = (data['is_zero'] + data['is_negative'] + data['is_spike'] > 0).astype(int)\n",
    "    \n",
    "    # Split into actuals and forecast\n",
    "    actuals = data[data['type_name'] == \"Demand\"]\n",
    "    forecast = data[data['type_name'] == \"Day-ahead demand forecast\"]\n",
    "    \n",
    "    # Merge actuals with forecast\n",
    "    joined = pd.merge(\n",
    "        actuals,\n",
    "        forecast.rename(columns={'value': 'forecast'}),\n",
    "        on=['respondent', 'period'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Rename columns to avoid suffixes like `_x` and `_y`\n",
    "    joined = joined.rename(columns={\n",
    "        'impute_x': 'impute',\n",
    "        'type_x': 'type',\n",
    "        'type_name_x': 'type_name',\n",
    "    })\n",
    "    \n",
    "    # Add imputed values\n",
    "    joined['imputed'] = np.where(\n",
    "        (joined['impute'] == 1) & ~joined['forecast'].isna(),\n",
    "        joined['forecast'],\n",
    "        np.where(\n",
    "            (joined['impute'] == 1) & joined['forecast'].isna() & ~joined['forecast'].shift(1).isna(),\n",
    "            joined['forecast'].shift(1),\n",
    "            np.where(\n",
    "                (joined['impute'] == 1) & joined['forecast'].isna() & joined['forecast'].shift(1).isna(),\n",
    "                joined['value'].shift(1),\n",
    "                joined['value']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Return cleaned data\n",
    "    return joined[['respondent', 'period', 'type', 'type_name', 'imputed']].rename(\n",
    "        columns={'imputed': 'value'}\n",
    "    ).drop_duplicates()\n",
    "data_marked = mark_anomalies(data)\n",
    "data_imputed = impute_data(data_marked)\n",
    "\n",
    "# Save the updated dataset\n",
    "compress_to_zip(\"data_imputed\",data_imputed)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"{i+1} of 5\")\n",
    "    data_marked = mark_anomalies(data_marked)\n",
    "    data_imputed = impute_data(data_marked)\n",
    "\n",
    "raw_imputed = pd.merge(data, data_imputed.rename(columns={'value': 'imputed'}),\n",
    "                       on=['respondent', 'type', 'type_name', 'period'], how='left')\n",
    "raw_imputed['is_imputed'] = (raw_imputed['value'] != raw_imputed['imputed']).astype(int)\n",
    "\n",
    "compress_to_zip(\"raw_imputed\",raw_imputed)\n",
    "\n",
    "print(raw_imputed['is_imputed'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fb0e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved and compressed into: ./data/MAPE.zip\n",
      "Files extracted to: ./data/eia_930_edges.csv\n",
      "DataFrame saved and compressed into: ./data/edges_with_MAPE.zip\n",
      "    node1 node2 respondent_x  MAPE_node1 respondent_y  MAPE_node2  abs_diff\n",
      "7    AECI   SPA         AECI    0.036209          SPA    1.044349  1.008140\n",
      "239   SPA  AECI          SPA    1.044349         AECI    0.036209  1.008140\n",
      "95   PSCO   PNM         PSCO    0.723519          PNM    0.063648  0.659871\n",
      "252   PNM  PSCO          PNM    0.063648         PSCO    0.723519  0.659871\n",
      "113  PSCO  WACM         PSCO    0.723519         WACM    0.142075  0.581444\n",
      "..    ...   ...          ...         ...          ...         ...       ...\n",
      "31   GCPD  BPAT         GCPD    0.023107         BPAT    0.020857  0.002250\n",
      "127  BPAT   AVA         BPAT    0.020857          AVA    0.019132  0.001726\n",
      "26    AVA  BPAT          AVA    0.019132         BPAT    0.020857  0.001726\n",
      "226   TEC  FMPP          TEC    0.046723         FMPP    0.045600  0.001123\n",
      "219  FMPP   TEC         FMPP    0.045600          TEC    0.046723  0.001123\n",
      "\n",
      "[192 rows x 7 columns]\n",
      "Duplicates found in actuals before pivot:\n",
      "        respondent type type_name              period    value  revision_id  \\\n",
      "88              NE    D    Demand 2022-01-01 00:00:00  14859.0       302352   \n",
      "89             PNM    D    Demand 2022-01-01 00:00:00   1754.0       302352   \n",
      "90            LDWP    D    Demand 2022-01-01 00:00:00   2662.0       302352   \n",
      "91            BPAT    D    Demand 2022-01-01 00:00:00   8535.0       302352   \n",
      "92            CISO    D    Demand 2022-01-01 00:00:00  22618.0       302352   \n",
      "...            ...  ...       ...                 ...      ...          ...   \n",
      "2942730       BANC    D    Demand 2024-07-05 06:00:00   3115.0       579043   \n",
      "2942731       CPLW    D    Demand 2024-07-05 06:00:00    504.0       579043   \n",
      "2942732       TIDC    D    Demand 2024-07-05 06:00:00    520.0       579043   \n",
      "2942733        DUK    D    Demand 2024-07-05 06:00:00  12678.0       579043   \n",
      "2942734        TAL    D    Demand 2024-07-05 06:00:00    346.0       579043   \n",
      "\n",
      "               id           state  Monday  Tuesday  Wednesday  Thursday  \\\n",
      "88              1        Nebraska       0        0          0         0   \n",
      "89              2      New Mexico       0        0          0         0   \n",
      "90              3      California       0        0          0         0   \n",
      "91              4      Washington       0        0          0         0   \n",
      "92              5      California       0        0          0         0   \n",
      "...           ...             ...     ...      ...        ...       ...   \n",
      "2942730  17026256      California       0        0          0         0   \n",
      "2942731  17026257           Texas       0        0          0         0   \n",
      "2942732  17026258           Texas       0        0          0         0   \n",
      "2942733  17026259  North Carolina       0        0          0         0   \n",
      "2942734  17026260         Florida       0        0          0         0   \n",
      "\n",
      "         Friday  Sunday  is_zero  is_negative  is_spike  impute  imputed  \\\n",
      "88            0       0        0            0         0       0  14859.0   \n",
      "89            0       0        0            0         0       0   1754.0   \n",
      "90            0       0        0            0         0       0   2662.0   \n",
      "91            0       0        0            0         0       0   8535.0   \n",
      "92            0       0        0            0         0       0  22618.0   \n",
      "...         ...     ...      ...          ...       ...     ...      ...   \n",
      "2942730       1       0        0            0         0       0   3115.0   \n",
      "2942731       1       0        0            0         0       0    504.0   \n",
      "2942732       1       0        0            0         0       0    520.0   \n",
      "2942733       1       0        0            0         0       0  12678.0   \n",
      "2942734       1       0        0            0         0       0    346.0   \n",
      "\n",
      "         is_imputed  \n",
      "88                0  \n",
      "89                0  \n",
      "90                0  \n",
      "91                0  \n",
      "92                0  \n",
      "...             ...  \n",
      "2942730           0  \n",
      "2942731           0  \n",
      "2942732           0  \n",
      "2942733           0  \n",
      "2942734           0  \n",
      "\n",
      "[6203 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate MAPEs\n",
    "actuals = raw_imputed[raw_imputed['type_name'] == \"Demand\"]\n",
    "forecast = raw_imputed[raw_imputed['type_name'] == \"Day-ahead demand forecast\"]\n",
    "joined = pd.merge(actuals, forecast[['respondent', 'period', 'value']].rename(columns={'value': 'forecast'}),\n",
    "                  on=['respondent', 'period'], how='left')\n",
    "joined['abs_error'] = np.abs(joined['value'] - joined['forecast']) / np.abs(joined['value'])\n",
    "\n",
    "MAPE = joined[joined['abs_error'] != np.inf].groupby('respondent')['abs_error'].mean().reset_index(name='MAPE')\n",
    "compress_to_zip(\"MAPE\",MAPE)\n",
    "\n",
    "# Load edges and calculate correlations\n",
    "edges = extract_zip(\"eia_930_edges\")\n",
    "exclude = [\"CISO\", \"ERCO\", \"SWPP\", \"MISO\", \"NYIS\", \"ISNE\", \"CAL\", \"PJM\"]\n",
    "\n",
    "edges = edges.merge(MAPE, left_on=\"node1\", right_on=\"respondent\").rename(columns={\"MAPE\": \"MAPE_node1\"})\n",
    "edges = edges.merge(MAPE, left_on=\"node2\", right_on=\"respondent\").rename(columns={\"MAPE\": \"MAPE_node2\"})\n",
    "edges['abs_diff'] = np.abs(edges['MAPE_node1'] - edges['MAPE_node2'])\n",
    "edges = edges.query(\"~node1.isin(@exclude) & ~node2.isin(@exclude)\").sort_values('abs_diff', ascending=False)\n",
    "compress_to_zip(\"edges_with_MAPE\",edges)\n",
    "print(edges)\n",
    "\n",
    "# Wide format and correlation matrix\n",
    "duplicates = actuals[actuals.duplicated(subset=['period', 'respondent'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates found in actuals before pivot:\")\n",
    "    print(duplicates)\n",
    "    # dedup\n",
    "    actuals = actuals.drop_duplicates(subset=['period', 'respondent'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20542a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respondent      AECI       AVA      AZPS      BANC      BPAT       CAL  \\\n",
      "respondent                                                               \n",
      "AECI        1.000000  0.557731  0.308503  0.373136  0.512310  0.251463   \n",
      "AVA         0.557731  1.000000  0.071045  0.356518  0.942282  0.239249   \n",
      "AZPS        0.308503  0.071045  1.000000  0.815741  0.003894  0.791049   \n",
      "BANC        0.373136  0.356518  0.815741  1.000000  0.293236  0.878408   \n",
      "BPAT        0.512310  0.942282  0.003894  0.293236  1.000000  0.176209   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "TVA         0.797252  0.404350  0.489897  0.512612  0.357459  0.369879   \n",
      "US48        0.717378  0.431817  0.695393  0.708961  0.360759  0.582142   \n",
      "WACM        0.289553  0.468788  0.308211  0.338997  0.406905  0.244657   \n",
      "WALC        0.124428 -0.128594  0.688994  0.570709 -0.168939  0.512349   \n",
      "WAUW        0.642405  0.736001  0.338746  0.484163  0.676043  0.417565   \n",
      "\n",
      "respondent       CAR      CENT      CHPD      CISO  ...       TEN      TEPC  \\\n",
      "respondent                                          ...                       \n",
      "AECI        0.646799  0.782936  0.531905  0.211368  ...  0.797038  0.357361   \n",
      "AVA         0.340112  0.414165  0.829077  0.205714  ...  0.404205  0.103178   \n",
      "AZPS        0.507912  0.668303 -0.209178  0.769579  ...  0.490314  0.909207   \n",
      "BANC        0.512089  0.648483  0.029110  0.840067  ...  0.512630  0.737478   \n",
      "BPAT        0.284407  0.348945  0.857851  0.152089  ...  0.357386  0.046146   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "TVA         0.897545  0.837036  0.255898  0.322291  ...  0.999999  0.508151   \n",
      "US48        0.892530  0.928611  0.160214  0.527250  ...  0.906653  0.683009   \n",
      "WACM        0.299967  0.411225  0.376464  0.249374  ...  0.279880  0.284825   \n",
      "WALC        0.355935  0.465931 -0.429290  0.465290  ...  0.348424  0.650285   \n",
      "WAUW        0.516668  0.623675  0.579968  0.381339  ...  0.542914  0.314832   \n",
      "\n",
      "respondent       TEX      TIDC      TPWR       TVA      US48      WACM  \\\n",
      "respondent                                                               \n",
      "AECI        0.518217  0.286387  0.433303  0.797252  0.717378  0.289553   \n",
      "AVA         0.186889  0.185116  0.877830  0.404350  0.431817  0.468788   \n",
      "AZPS        0.753437  0.869974 -0.203444  0.489897  0.695393  0.308211   \n",
      "BANC        0.652597  0.939640  0.111524  0.512612  0.708961  0.338997   \n",
      "BPAT        0.115426  0.114120  0.926417  0.357459  0.360759  0.406905   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "TVA         0.727036  0.482460  0.208124  1.000000  0.906785  0.279217   \n",
      "US48        0.867982  0.699607  0.180468  0.906785  1.000000  0.373924   \n",
      "WACM        0.324079  0.236095  0.254916  0.279217  0.373924  1.000000   \n",
      "WALC        0.610413  0.663277 -0.283244  0.348004  0.503156 -0.149298   \n",
      "WAUW        0.382380  0.379674  0.565031  0.543018  0.620350  0.378461   \n",
      "\n",
      "respondent      WALC      WAUW  \n",
      "respondent                      \n",
      "AECI        0.124428  0.642405  \n",
      "AVA        -0.128594  0.736001  \n",
      "AZPS        0.688994  0.338746  \n",
      "BANC        0.570709  0.484163  \n",
      "BPAT       -0.168939  0.676043  \n",
      "...              ...       ...  \n",
      "TVA         0.348004  0.543018  \n",
      "US48        0.503156  0.620350  \n",
      "WACM       -0.149298  0.378461  \n",
      "WALC        1.000000  0.128870  \n",
      "WAUW        0.128870  1.000000  \n",
      "\n",
      "[67 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform pivot operation\n",
    "actuals_wide = actuals.pivot(index='period', columns='respondent', values='imputed')\n",
    "correlation_matrix = actuals_wide.corr(method='pearson', min_periods=1)\n",
    "correlation_matrix.to_csv(\"./data/correlation_matrix.csv\", index=True) \n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple LDWP Model\n",
    "relevant_cols = ['CISO', 'BPAT', 'LDWP', 'PACE', 'NEVP', 'AZPS', 'WALC']\n",
    "reg_data = actuals_wide[relevant_cols].dropna()\n",
    "reg_data['LDWP_lag1'] = reg_data['LDWP'].shift(1)\n",
    "reg_data['LDWP_lag24'] = reg_data['LDWP'].shift(24)\n",
    "\n",
    "reg_data = reg_data.dropna()\n",
    "X = reg_data[['LDWP_lag1', 'LDWP_lag24', 'CISO', 'BPAT', 'PACE', 'NEVP', 'AZPS', 'WALC']]\n",
    "y = reg_data['LDWP']\n",
    "\n",
    "# Define hyperparameter grids for GridSearchCV\n",
    "linear_param_grid = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, shuffle=True, random_state=614\n",
    "        )\n",
    "\n",
    "# Model 1: Linear Regression with GridSearchCV and Cross-Validation\n",
    "linear_model = LinearRegression()\n",
    "linear_grid_search = GridSearchCV(linear_model, linear_param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "linear_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation for Linear Regression\n",
    "linear_cv_results = cross_validate(linear_grid_search.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "linear_mean_score = linear_cv_results['test_score'].mean()\n",
    "\n",
    "# Best Linear Regression Model\n",
    "best_linear_model = linear_grid_search.best_estimator_\n",
    "linear_predictions = best_linear_model.predict(X_test)\n",
    "linear_mape = mean_absolute_percentage_error(y_test, linear_predictions)\n",
    "with open(\"./models/linear_regression_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_linear_model, f)\n",
    "print(\"Best Linear Regression Model saved successfully.\")\n",
    "\n",
    "# Model 2: Random Forest Regressor with GridSearchCV and Cross-Validation\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation for Random Forest\n",
    "rf_cv_results = cross_validate(rf_grid_search.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "rf_mean_score = rf_cv_results['test_score'].mean()\n",
    "\n",
    "# Best Random Forest Model\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "rf_mape = mean_absolute_percentage_error(y_test, rf_predictions)\n",
    "with open(\"./models/random_forest_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_rf_model, f)\n",
    "print(\"Best Random Forest Model saved successfully.\")\n",
    "\n",
    "# Model 3: Gradient Boosting Regressor with GridSearchCV and Cross-Validation\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_grid_search = GridSearchCV(gb_model, gb_param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation for Gradient Boosting\n",
    "gb_cv_results = cross_validate(gb_grid_search.best_estimator_, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "gb_mean_score = gb_cv_results['test_score'].mean()\n",
    "\n",
    "# Best Gradient Boosting Model\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "gb_predictions = best_gb_model.predict(X_test)\n",
    "gb_mape = mean_absolute_percentage_error(y_test, gb_predictions)\n",
    "with open(\"./models/gradient_boosting_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_gb_model, f)\n",
    "print(\"Best Gradient Boosting Model saved successfully.\")\n",
    "\n",
    "# Compare model accuracy\n",
    "print(\"Model Performance (MAPE):\")\n",
    "print(f\"Linear Regression: {linear_mape:.4f}, Cross-Validation Mean: {linear_mean_score:.4f}\")\n",
    "print(f\"Random Forest Regressor: {rf_mape:.4f}, Cross-Validation Mean: {rf_mean_score:.4f}\")\n",
    "print(f\"Gradient Boosting Regressor: {gb_mape:.4f}, Cross-Validation Mean: {gb_mean_score:.4f}\")\n",
    "\n",
    "# Evaluation results dictionary\n",
    "evaluation_results = {\n",
    "    \"Linear Regression\": {\"MAPE\": linear_mape, \"Cross-Validation Mean\": linear_mean_score},\n",
    "    \"Random Forest\": {\"MAPE\": rf_mape, \"Cross-Validation Mean\": rf_mean_score},\n",
    "    \"Gradient Boosting\": {\"MAPE\": gb_mape, \"Cross-Validation Mean\": gb_mean_score},\n",
    "}\n",
    "\n",
    "# Save evaluation results to JSON\n",
    "with open(\"./data/evaluation_results.json\", \"w\") as file:\n",
    "    json.dump(evaluation_results, file)\n",
    "\n",
    "print(\"Evaluation results saved successfully.\")\n",
    "\n",
    "# Print model coefficients or feature importances\n",
    "print(\"Linear Model Coefficients:\", best_linear_model.coef_)\n",
    "print(\"Random Forest Feature Importances:\", best_rf_model.feature_importances_)\n",
    "print(\"Gradient Boosting Feature Importances:\", best_gb_model.feature_importances_)\n",
    "\n",
    "print(\"Results saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8916fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AECI', 'AVA', 'AZPS', 'BANC', 'BPAT', 'CAL', 'CAR', 'CENT', 'CHPD',\n",
      "       'CISO', 'CPLE', 'CPLW', 'DOPD', 'DUK', 'EPE', 'ERCO', 'FLA', 'FMPP',\n",
      "       'FPC', 'FPL', 'GCPD', 'GVL', 'HST', 'IID', 'IPCO', 'ISNE', 'JEA',\n",
      "       'LDWP', 'LGEE', 'MIDA', 'MIDW', 'MISO', 'NE', 'NEVP', 'NW', 'NWMT',\n",
      "       'NY', 'NYIS', 'PACE', 'PACW', 'PGE', 'PJM', 'PNM', 'PSCO', 'PSEI', 'SC',\n",
      "       'SCEG', 'SCL', 'SE', 'SEC', 'SOCO', 'SPA', 'SRP', 'SW', 'SWPP', 'TAL',\n",
      "       'TEC', 'TEN', 'TEPC', 'TEX', 'TIDC', 'TPWR', 'TVA', 'US48', 'WACM',\n",
      "       'WALC', 'WAUW'],\n",
      "      dtype='object', name='respondent')\n"
     ]
    }
   ],
   "source": [
    "# edges = extract_zip(\"correlation_matrix\")\n",
    "# print(edges)\n",
    "data = pd.read_csv(\"./data/correlation_matrix.csv\", index_col=0)\n",
    "print(data.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
